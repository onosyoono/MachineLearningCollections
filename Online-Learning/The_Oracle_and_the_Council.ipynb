{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The Oracle and the Council.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwqB/IOChEaeT6f8RSmVge",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmanPriyanshu/Discussing_Learning/blob/master/The_Oracle_and_the_Council.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RndK_SDlzypB",
        "colab_type": "text"
      },
      "source": [
        "## THE ORACLE:\n",
        "\n",
        "The actual labels of the datsets, i.e. something which can give classification within 100% accuracy.\n",
        "\n",
        "## COUNCIL:\n",
        "Number of members exist within the council. They vote for labels and upon discrepencies ask from the Oracle.\n",
        "\n",
        "Members:\n",
        "\n",
        "* Random Forest (max_depth=4)\n",
        "* Random Forest (max_depth=8)\n",
        "* Random Forest (max_depth=12)\n",
        "* Naive Bayes\n",
        "* Perceptron\n",
        "* ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clz-lp9G15AN",
        "colab_type": "text"
      },
      "source": [
        "## UPLOADING DATASET:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCOvRoWZ17mi",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f2480abe-8046-4366-ffd2-46e554214552"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c9dc9545-04f3-4e0a-8dc6-53958d1de991\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c9dc9545-04f3-4e0a-8dc6-53958d1de991\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1IgMWbv11bM",
        "colab_type": "text"
      },
      "source": [
        "## IMPORTS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQs7W9g4xleY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from math import factorial\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upd1IavU3up7",
        "colab_type": "text"
      },
      "source": [
        "## LOADING DATA:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhK23NGo3txW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "features = data.columns\n",
        "data = data.values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMm8e5lR35-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "da52e09d-4741-4437-8020-43c43d609a87"
      },
      "source": [
        "print(features)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
            "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
            "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
            "       'touch_screen', 'wifi', 'price_range'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0jmWjEU37Ag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "4328d9c5-818c-4d30-f771-bae869b84010"
      },
      "source": [
        "X = data.T[:-1]\n",
        "Y = data.T[-1]\n",
        "X = X.T\n",
        "\n",
        "indexes = np.arange(X.shape[0])\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indexes)\n",
        "X = X[indexes]\n",
        "Y = Y[indexes]\n",
        "\n",
        "Y_encoded = []\n",
        "for y in Y:\n",
        "  a = [0, 0, 0, 0]\n",
        "  a[int(y)] = 1\n",
        "  Y_encoded.append(a)\n",
        "Y_encoded = np.array(Y_encoded)\n",
        "Y = Y_encoded\n",
        "\n",
        "print('X', X.shape,'\\n', X)\n",
        "print()\n",
        "print('Y',Y.shape,'\\n', Y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (2000, 20) \n",
            " [[1.454e+03 1.000e+00 5.000e-01 ... 1.000e+00 1.000e+00 0.000e+00]\n",
            " [1.092e+03 1.000e+00 5.000e-01 ... 0.000e+00 1.000e+00 0.000e+00]\n",
            " [1.524e+03 1.000e+00 1.800e+00 ... 1.000e+00 0.000e+00 1.000e+00]\n",
            " ...\n",
            " [1.190e+03 0.000e+00 2.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
            " [1.191e+03 0.000e+00 2.400e+00 ... 1.000e+00 1.000e+00 1.000e+00]\n",
            " [7.060e+02 0.000e+00 5.000e-01 ... 1.000e+00 0.000e+00 1.000e+00]]\n",
            "\n",
            "Y (2000, 4) \n",
            " [[0 0 0 1]\n",
            " [1 0 0 0]\n",
            " [0 0 1 0]\n",
            " ...\n",
            " [0 0 0 1]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0JzcKSK4aNN",
        "colab_type": "text"
      },
      "source": [
        "Let the Oracle have the Y values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eGaUxlf6Gl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_X = X\n",
        "original_Y = Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg6sMCJA4HYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Oracle(X_quest):\n",
        "  global original_X, original_Y\n",
        "  real_Y = []\n",
        "  for x_q in X_quest:\n",
        "    for x, y in zip(original_X, original_Y):\n",
        "      if np.sum(x-x_q)==0:\n",
        "        real_Y.append(y)\n",
        "        break\n",
        "  real_Y = np.array(real_Y)\n",
        "  return real_Y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sER94Znt62Ky",
        "colab_type": "text"
      },
      "source": [
        "## CREATING A COUNCIL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiTkTVq76svL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassifierCouncil:\n",
        "  def __init__(self, X, threshold=0.2, seed=0, y_shape=4, max_iter=1e1):\n",
        "    self.max_iter = max_iter\n",
        "    self.iter = 0\n",
        "    self.X = X\n",
        "    self.threshold = threshold + 1e-4\n",
        "    np.random.seed(seed=seed)\n",
        "    indexes = np.arange(self.X.shape[0])\n",
        "    np.random.shuffle(indexes)\n",
        "    self.X = self.X[indexes]\n",
        "    self.clf0 = RandomForestClassifier(max_depth=4, random_state=0)\n",
        "    self.clf1 = RandomForestClassifier(max_depth=8, random_state=0)\n",
        "    self.clf2 = RandomForestClassifier(max_depth=12, random_state=0)\n",
        "    self.neigh = KNeighborsClassifier(n_neighbors=int(X.shape[0]**0.5)//2)\n",
        "    self.perceptron = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(y_shape, activation='softmax', input_shape=(X.shape[1],))\n",
        "                                    ])\n",
        "    self.perceptron.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    self.ann = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(X.shape[1]//2, activation='sigmoid', input_shape=(X.shape[1],)),\n",
        "                                    tf.keras.layers.Dense(y_shape, activation='softmax', input_shape=(X.shape[1],))\n",
        "                                    ])\n",
        "    self.ann.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    self.indexes_labelled = None\n",
        "\n",
        "  def first(self):\n",
        "    self.indexes_labelled = np.arange(int(self.X.shape[0]**0.5))\n",
        "    first_x = self.X[:int(self.X.shape[0]**0.5)]\n",
        "    first_y = Oracle(first_x)\n",
        "    self.clf0.fit(first_x, first_y)\n",
        "    self.clf1.fit(first_x, first_y)\n",
        "    self.clf2.fit(first_x, first_y)\n",
        "    self.neigh.fit(first_x, first_y)\n",
        "    self.perceptron.fit(first_x, first_y, epochs=1000, verbose=0)\n",
        "    self.ann.fit(first_x, first_y, epochs=1000, verbose=0)\n",
        "  \n",
        "  def current_predictions(self):\n",
        "    y_clf0 = self.clf0.predict(self.X)\n",
        "    y_clf1 = self.clf1.predict(self.X)\n",
        "    y_clf2 = self.clf2.predict(self.X)\n",
        "    y_neigh = self.neigh.predict(self.X)\n",
        "    y_perceptron = self.perceptron.predict(self.X)\n",
        "\n",
        "    y_perceptron_encoded = []\n",
        "    for y in y_perceptron:\n",
        "      a = [0 for i in range(y.shape[0])]\n",
        "      a[np.argmax(y)] = 1\n",
        "      y_perceptron_encoded.append(a)\n",
        "    y_perceptron = np.array(y_perceptron_encoded)\n",
        "\n",
        "    y_ann = self.ann.predict(self.X)\n",
        "\n",
        "    y_ann_encoded = []\n",
        "    for y in y_ann:\n",
        "      a = [0 for i in range(y.shape[0])]\n",
        "      a[np.argmax(y)] = 1\n",
        "      y_ann_encoded.append(a)\n",
        "    y_ann = np.array(y_ann_encoded)\n",
        "\n",
        "    return y_clf0, y_clf1, y_clf2, y_neigh, y_perceptron, y_ann\n",
        "\n",
        "  def discrepency_calc(self):\n",
        "    y_clf0, y_clf1, y_clf2, y_neigh, y_perceptron, y_ann = self.current_predictions()\n",
        "    discrep = []\n",
        "    for c1, c2, c3, c4, c5, c6 in zip(y_clf0, y_clf1, y_clf2, y_neigh, y_perceptron, y_ann):\n",
        "      score = abs(np.sum(c1-c2)/2) + abs(np.sum(c1-c3)/2) + abs(np.sum(c1-c4)/2) + abs(np.sum(c1-c5)/2) + abs(np.sum(c1-c6)/2) + abs(np.sum(c2-c3)/2) \n",
        "      score += abs(np.sum(c2-c4)/2) + abs(np.sum(c2-c5)/2) + abs(np.sum(c2-c6)/2) + abs(np.sum(c3-c4)/2) + abs(np.sum(c3-c5)/2) + abs(np.sum(c3 - c6)/2)\n",
        "      score += abs(np.sum(c4-c5)/2) + abs(np.sum(c4-c6)/2) + abs(np.sum(c5-c6)/2)\n",
        "      score = score/(factorial(6)/(factorial(2)*factorial(4)))\n",
        "      discrep.append(score)\n",
        "    discrep = np.array(discrep)\n",
        "    return discrep\n",
        "\n",
        "  def learn_again(self):\n",
        "    x = self.X[self.indexes_labelled]\n",
        "    y = Oracle(x)\n",
        "    self.clf0.fit(x, y)\n",
        "    self.clf1.fit(x, y)\n",
        "    self.clf2.fit(x, y)\n",
        "    self.neigh.fit(x, y)\n",
        "    self.perceptron.fit(x, y, epochs=1000, verbose=0)\n",
        "    self.ann.fit(x, y, epochs=1000, verbose=0)\n",
        "\n",
        "  def predict(self, x_user):\n",
        "    y_clf0 = self.clf0.predict(x_user)\n",
        "    y_clf1 = self.clf1.predict(x_user)\n",
        "    y_clf2 = self.clf2.predict(x_user)\n",
        "    y_neigh = self.neigh.predict(x_user)\n",
        "    y_perceptron = self.perceptron.predict(x_user)\n",
        "\n",
        "    y_perceptron_encoded = []\n",
        "    for y in y_perceptron:\n",
        "      a = [0 for i in range(y.shape[0])]\n",
        "      a[np.argmax(y)] = 1\n",
        "      y_perceptron_encoded.append(a)\n",
        "    y_perceptron = np.array(y_perceptron_encoded)\n",
        "\n",
        "    y_ann = self.ann.predict(self.X)\n",
        "\n",
        "    y_ann_encoded = []\n",
        "    for y in y_ann:\n",
        "      a = [0 for i in range(y.shape[0])]\n",
        "      a[np.argmax(y)] = 1\n",
        "      y_ann_encoded.append(a)\n",
        "    y_ann = np.array(y_ann_encoded)\n",
        "\n",
        "    y_user_base = y_clf0 + y_clf1 + y_clf2 + y_neigh + y_perceptron + y_ann\n",
        "    y_user = []\n",
        "    for y in y_user_base:\n",
        "      a = [0 for i in range(y.shape[0])]\n",
        "      a[np.argmax(y)] = 1\n",
        "      y_user.append(a)\n",
        "    y_user = np.array(y_user)\n",
        "    return y_user\n",
        "\n",
        "  def calling_oracle(self):\n",
        "    discrep = self.discrepency_calc()\n",
        "    indexes_sorted = np.argsort(discrep)[::-1]\n",
        "    score = np.mean(discrep)\n",
        "    print('Current Discrepency Score within the Council', score, 'Number of training samples used', self.indexes_labelled.shape, 'Worst Cases Used:', np.mean(discrep[indexes_sorted][:int(self.X.shape[0]**0.5)//2]))\n",
        "    if discrep[indexes_sorted][0] < self.threshold or self.iter > self.max_iter:\n",
        "      print(discrep[indexes_sorted], self.indexes_labelled.shape)\n",
        "      return True\n",
        "    else:\n",
        "      self.indexes_labelled = np.array(list(set([i for i in np.concatenate([self.indexes_labelled, indexes_sorted[:int(self.X.shape[0]**0.5)//2]]).flatten()])))\n",
        "      self.learn_again()\n",
        "    self.iter += 1\n",
        "    self.calling_oracle()  \n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-kuR_l69KfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "dd30c351-beaf-4e47-9a6e-8c9c37fb327e"
      },
      "source": [
        "council = ClassifierCouncil(X)\n",
        "council.first()\n",
        "council.calling_oracle()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Discrepency Score within the Council 0.2455333333333333 Number of training samples used (44,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.1914 Number of training samples used (66,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.20549999999999993 Number of training samples used (88,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.20541666666666666 Number of training samples used (110,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.1613 Number of training samples used (132,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.16385 Number of training samples used (154,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.15783333333333333 Number of training samples used (176,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.18939999999999999 Number of training samples used (198,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.18994999999999998 Number of training samples used (220,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.19409999999999997 Number of training samples used (242,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.19391666666666663 Number of training samples used (264,) Worst Cases Used: 0.29999999999999993\n",
            "Current Discrepency Score within the Council 0.1959333333333333 Number of training samples used (286,) Worst Cases Used: 0.29999999999999993\n",
            "[0.3 0.3 0.3 ... 0.  0.  0. ] (286,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bs59Bjr9Us_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = council.predict(original_X)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLpK2kGnSDaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1096867-da4b-44b5-d12e-b545039420ad"
      },
      "source": [
        "acc = 0\n",
        "for y0, y1 in zip(original_Y, Y_pred):\n",
        "  if np.sum(y0 - y1) == 0:\n",
        "    acc += 1\n",
        "acc = acc/original_Y.shape[0]\n",
        "print(acc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMLF5zd2TI_m",
        "colab_type": "text"
      },
      "source": [
        "ONLY 286 values can easily give us an accuracy of 100%. Let us just try it with an ANN with the first 286 values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnyYkuEcS0Kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(X.shape[1]//2, activation='sigmoid', input_shape=(X.shape[1],)),\n",
        "                                    tf.keras.layers.Dense(original_Y.shape[1], activation='softmax', input_shape=(X.shape[1],))\n",
        "                                    ])\n",
        "ann.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIIkUHGpTbIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02050ce6-f36c-4244-c8a2-e6e9789c4bc4"
      },
      "source": [
        "ann.fit(original_X[:286], original_Y[:286], epochs=1000, verbose=0)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fec372c9a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68d2IrZqTmiK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "43a67377-233a-470c-9ee8-e4081fb14ec9"
      },
      "source": [
        "print(ann.evaluate(original_X, original_Y, verbose=1))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 1.0388 - accuracy: 0.5265\n",
            "[1.0388219356536865, 0.5264999866485596]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WggVj7vKUJEM",
        "colab_type": "text"
      },
      "source": [
        "That is poor accuracy maybe ANN isn't the best model. Let us try the Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYBadeSsT9qM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3d060f4-4255-408d-b831-894ee6556388"
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=12, random_state=0)\n",
        "clf.fit(original_X[:286], original_Y[:286])\n",
        "print(clf.score(original_X, original_Y))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esf2TkLCUsaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "76a7d2d8-9db9-4c83-e6ad-a60695ba0a65"
      },
      "source": [
        "print(original_Y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 1]\n",
            " [1 0 0 0]\n",
            " [0 0 1 0]\n",
            " ...\n",
            " [0 0 0 1]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_fUWD-U_yU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "933d861c-fc4b-4bee-887f-084b8d3cacd0"
      },
      "source": [
        "print(Y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 1]\n",
            " [1 0 0 0]\n",
            " [0 0 1 0]\n",
            " ...\n",
            " [0 0 0 1]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsulQJK2VFvD",
        "colab_type": "text"
      },
      "source": [
        "Ok I don't know how this is working but yes we get a 100% accuracy with only 286 samples from the 2000 data points we have. Now, I know this is stupid to perform because we already have the true values. Why would we have an Oracle system at all? This is because, the oracle system is seperate and is actually step-in for Human here. That means that the labelling is extremely expensive, since human time is expensive. We first ask the human to randomly return to us a few values, we then begin to predict on the basis of that. And only ask really important parts. The models select only those points which are considered confusing for the model. It will be useful when one just starts creating a dataset, and wants to start analysing immediately. It also reduces training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fc6A9P3VEcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}